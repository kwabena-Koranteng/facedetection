<!DOCTYPE html>
<html>
  <head>
    <meta charset="utf-8" />
    <title>Simple Video Capture Example</title>
  </head>
  <body>
    <div>
      <div class="inputoutput">
        <div class="control"><button id="startAndStop">Start</button></div>
        <div class="camera">
          <video id="videoInput" width="320" height="240"></video>
          <canvas id="canvasOutput" width="320" height="240"></canvas>
        </div>
      </div>
    </div>
    <script
      async
      src="https://docs.opencv.org/3.4.0/opencv.js"
      onload="onOpenCvReady();"
      type="text/javascript"
    ></script>

    <script type="text/javascript">
      function onOpenCvReady() {
        if (cv.getBuildInformation) {
        //   console.log(cv.getBuildInformation());
          onloadCallback();
        } else {
          //wait for opencv.js compilation;
          cv["onRuntimeInitialized"] = () => {
            console.log(cv.getBuildInformation());
            onloadCallback();
          };
        }
      }
      function onloadCallback() {
        let streaming = false;
        let startAndStop = document.getElementById("startAndStop");
        let canvasOutput = document.getElementById("canvasOutput");
        let canvasContext = canvasOutput.getContext("2d");

        startAndStop.addEventListener("click", () => {
          if (!streaming) {
            startCamera("qvga", onVideoStarted, "videoInput");
          } else {
            stopCamera();
            onVideoStopped();
          }
        });

        function onVideoStarted() {
          streaming = true;
          startAndStop.innerText = "Stop";

          /**Your example code here*/
          let video = document.getElementById("videoInput");
          let src = new cv.Mat(video.height, video.width, cv.CV_8UC4);
          let dst = new cv.Mat(video.height, video.width, cv.CV_8UC1);
          let gray = new cv.Mat();
          let cap = new cv.VideoCapture(video);
          let faces = new cv.RectVector();
          let classifier = new cv.CascadeClassifier();

// load pre-trained classifiers
        classifier.load('https://raw.githubusercontent.com/opencv/opencv/master/data/haarcascades/haarcascade_frontalcatface.xml');

          const FPS = 30;
          function processVideo() {
            try {
              if (!streaming) {
                // clean and stop.
                src.delete();
                dst.delete();
                return;
              }
              let begin = Date.now();
              // start processing.
              cap.read(src);
              cv.cvtColor(src, dst, cv.COLOR_RGBA2GRAY);
              classifier.detectMultiScale(gray, faces, 1.1, 3, 0);
        //   // draw faces.
            for (let i = 0; i < faces.size(); ++i) {
              let face = faces.get(i);
              let point1 = new cv.Point(face.x, face.y);
              let point2 = new cv.Point(face.x + face.width, face.y + face.height);
              cv.rectangle(dst, point1, point2, [255, 0, 0, 255]);
          }
       
              cv.imshow("canvasOutput", dst);
              // schedule the next one.
              let delay = 1000 / FPS - (Date.now() - begin);
              setTimeout(processVideo, delay);
            } catch (err) {
            //   console.log(err);
              utils.printError(err);
            }
          }

          // schedule the first one.
          setTimeout(processVideo, 0);
        }

        function onVideoStopped() {
          streaming = false;
          canvasContext.clearRect(
            0,
            0,
            canvasOutput.width,
            canvasOutput.height
          );
          startAndStop.innerText = "Start";
        }
      }

      //utils
      startCamera = function (resolution, callback, videoId) {
        const constraints = {
          qvga: { width: { exact: 320 }, height: { exact: 240 } },
          vga: { width: { exact: 640 }, height: { exact: 480 } }
        };
        let video = document.getElementById(videoId);
        if (!video) {
          video = document.createElement("video");
        }

        let videoConstraint = constraints[resolution];
        if (!videoConstraint) {
          videoConstraint = true;
        }

        navigator.mediaDevices
          .getUserMedia({ video: videoConstraint, audio: false })
          .then(function (stream) {
            video.srcObject = stream;
            video.play();
            callback();
          })
          .catch(function (err) {
            console.log("An error occurred! " + err);
          });
      };

      stopCamera = function () {
        if (this.video) {
          this.video.pause();
          this.video.srcObject = null;
          this.video.removeEventListener("canplay", onVideoCanPlay);
        }
        if (this.stream) {
          this.stream.getVideoTracks()[0].stop();
        }
      };
    </script>
  </body>
</html>
